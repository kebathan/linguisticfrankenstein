data:
  corpus_1:
    path_src: "data/trial3/train_inputs_clean.txt"
    path_tgt: "data/trial3/train_targets_clean.txt"
  valid:
    path_src: "data/trial3/valid_inputs_clean.txt"
    path_tgt: "data/trial3/valid_targets_clean.txt"

src_vocab: "data/trial3/vocabulary_clean.txt"
tgt_vocab: "data/trial3/vocabulary_clean.txt"

save_model: "models/trial3/tamil"
encoder_type: "transformer"
decoder_type: "transformer"
src_word_vec_size: 128
tgt_word_vec_size: 128
hidden_size: 128
transformer_ff: 512
transformer_heads: 4

layers: 6
position_encoding: true
optim: "adam"
adam_beta1: 0.9
adam_beta2: 0.998
learning_rate: 2.0
warmup_steps: 400
max_grad_norm: 1.0

dropout: 0.1
label_smoothing: 0.1

train_steps: 1000
valid_steps: 100
batch_size: 32
batch_type: "tokens"
accum_count: 2

beam_size: 5
length_penalty: 1.0

world_size: 1
gpu_ranks: [0]

log_file: "data/trial3/training.log"
save_checkpoint_steps: 100
keep_checkpoint: 5
